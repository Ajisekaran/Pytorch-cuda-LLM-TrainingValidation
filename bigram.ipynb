{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82f2cc0b-d4d7-4daf-9ec9-719ac351a7cf",
   "metadata": {},
   "source": [
    "Experimentin with text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "364648a8-4de5-44a5-b792-c96037d4d2d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "252022\n"
     ]
    }
   ],
   "source": [
    "with open('wizard_of_oz.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "print(len(text))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46b84fdb-8d7f-44be-b7a6-de3965a24595",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Project Gutenberg eBook of Dorothy and the Wizard in Oz\n",
      "    \n",
      "This ebook is for the use of anyone anywhere in the United States and\n",
      "most other parts of the world at no cost and with almost no rest\n"
     ]
    }
   ],
   "source": [
    "print(text[:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6e35f03-4dc9-4d8c-bad3-4147f619515a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n', ' ', '!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '[', ']', '_', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '—', '‘', '’', '“', '”', '•', '™', '\\ufeff']\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(set(text))\n",
    "print(chars)\n",
    "vocabulary_size = len(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ac6cf41-1634-44f6-a5d8-0c92860fb305",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92\n"
     ]
    }
   ],
   "source": [
    "print(len(chars))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f310d9a-bcf6-4815-a549-db1f5e69f4c2",
   "metadata": {},
   "source": [
    "## character level Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "57c9a9c4-64cf-4e79-9d69-5de2381aab65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[65, 62, 69, 69, 72]\n"
     ]
    }
   ],
   "source": [
    "string_to_int = {ch: i for i, ch in enumerate(chars)}\n",
    "int_to_string = {i: ch for i,ch in enumerate(chars)}\n",
    "encode = lambda s: [string_to_int[c] for c in s]\n",
    "decode = lambda l: ''.join([int_to_string[i] for i in l])\n",
    "\n",
    "print(encode('hello'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c11ff951-6045-42bd-b35e-cfc3b01c4c5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "encoded_hello = encode('hello')\n",
    "decoded_hello = decode(encoded_hello)\n",
    "print(decoded_hello)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8d1c35-765a-40b9-91bb-cf9a78b258a2",
   "metadata": {},
   "source": [
    "Types of tokenizer = word level character level subword tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ceb8339-0061-4d6c-9494-2ac91963c191",
   "metadata": {},
   "source": [
    "# Tensor Instead of Arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b4de9470-af2a-4a27-a568-fdada909a63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eb420ea0-5fbf-4eea-a588-50fdd4dbff9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([91, 48, 65, 62,  1, 44, 75, 72, 67, 62, 60, 77,  1, 35, 78, 77, 62, 71,\n",
      "        59, 62, 75, 64,  1, 62, 30, 72, 72, 68,  1, 72, 63,  1, 32, 72, 75, 72,\n",
      "        77, 65, 82,  1, 58, 71, 61,  1, 77, 65, 62,  1, 51, 66, 83, 58, 75, 61,\n",
      "         1, 66, 71,  1, 43, 83,  0,  1,  1,  1,  1,  0, 48, 65, 66, 76,  1, 62,\n",
      "        59, 72, 72, 68,  1, 66, 76,  1, 63, 72, 75,  1, 77, 65, 62,  1, 78, 76,\n",
      "        62,  1, 72, 63,  1, 58, 71, 82, 72, 71])\n"
     ]
    }
   ],
   "source": [
    "data = torch.tensor(encode(text), dtype = torch.long)\n",
    "print(data[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f7143e-5161-4902-a054-cac8b1b1d182",
   "metadata": {},
   "source": [
    "## Train and Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581526cd-e241-4a47-a92e-06bac270d363",
   "metadata": {},
   "source": [
    "Train = 80%  Validation = 20%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "154a794b-6f48-4220-90e8-b7581604ecf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = int(0.8*len(data))\n",
    "train_data = data[:n]\n",
    "val_data = data[:n]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de04e0e9-2daf-4a43-bdd6-0e701647d298",
   "metadata": {},
   "source": [
    "Input and Targets Implementations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c3787998-4086-454e-b64a-398847c24a2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when input is tensor([91]) target is tensor(65)\n",
      "when input is tensor([91, 48]) target is tensor(65)\n",
      "when input is tensor([91, 48, 65]) target is tensor(65)\n",
      "when input is tensor([91, 48, 65, 62]) target is tensor(65)\n",
      "when input is tensor([91, 48, 65, 62,  1]) target is tensor(65)\n",
      "when input is tensor([91, 48, 65, 62,  1, 44]) target is tensor(65)\n",
      "when input is tensor([91, 48, 65, 62,  1, 44, 75]) target is tensor(65)\n",
      "when input is tensor([91, 48, 65, 62,  1, 44, 75, 72]) target is tensor(65)\n"
     ]
    }
   ],
   "source": [
    "block_size = 8\n",
    "\n",
    "x = train_data[:block_size]\n",
    "y = train_data[1:block_size+1]\n",
    "\n",
    "for t in range(block_size):\n",
    "    context = x[:t+1]\n",
    "    target = y[1]\n",
    "    print('when input is', context, 'target is', target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "224351fb-982c-462f-9487-c12f912cf462",
   "metadata": {},
   "source": [
    "switch from CPU to cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "856ba68c-030c-483c-9562-b2dac35bdd8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)\n",
    "block_size = 8\n",
    "batch_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f744d19b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\atcha\\anaconda3\\Lib\\site-packages\\torch\\utils\\_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3df769a4-6672-4eef-9e19-2c2e16c445d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, hidden_size, num_layers):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
    "        self.lstm = nn.LSTM(embed_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, vocab_size)\n",
    "    \n",
    "    def forward(self, x, hidden):\n",
    "        x = self.embedding(x)\n",
    "        out, hidden = self.lstm(x, hidden)\n",
    "        out = self.fc(out)\n",
    "        return out, hidden\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d25ccfe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = sorted(set(text))\n",
    "vocab_size = len(chars)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3ff2ded7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Size: 92\n"
     ]
    }
   ],
   "source": [
    "print(\"Vocabulary Size:\", vocab_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "48ca721f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "080226e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_size = 64\n",
    "hidden_size = 128\n",
    "num_layers = 2\n",
    "batch_size = 4\n",
    "block_size = 8\n",
    "epochs = 10\n",
    "learning_rate = 0.001\n",
    "\n",
    "model = CharModel(vocab_size, embed_size, hidden_size, num_layers).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "def get_batch(split):\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    idx = torch.randint(0, len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in idx]).to(device)\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in idx]).to(device)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ab8f0e77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 2.2120585441589355\n",
      "Epoch 2, Loss: 2.3547379970550537\n",
      "Epoch 3, Loss: 2.0613508224487305\n",
      "Epoch 4, Loss: 1.9459351301193237\n",
      "Epoch 5, Loss: 2.18825101852417\n",
      "Epoch 6, Loss: 2.267282485961914\n",
      "Epoch 7, Loss: 1.9814447164535522\n",
      "Epoch 8, Loss: 1.4452241659164429\n",
      "Epoch 9, Loss: 1.5366137027740479\n",
      "Epoch 10, Loss: 1.9444795846939087\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    for i in range(1000):  \n",
    "        x, y = get_batch('train')\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        hidden = (torch.zeros(num_layers, batch_size, hidden_size).to(device),\n",
    "                  torch.zeros(num_layers, batch_size, hidden_size).to(device))  \n",
    "\n",
    "        output, hidden = model(x, hidden)  \n",
    "        loss = criterion(output.view(-1, vocab_size), y.view(-1))\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f'Epoch {epoch+1}, Loss: {loss.item()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "838278cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time the child the child the child the child the child the child the child the child the child the child the child the child the child the child the child the child the child the child the child the child\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "def generate_text(start_string, length=200):\n",
    "    input_eval = torch.tensor([string_to_int[c] for c in start_string], dtype=torch.long).unsqueeze(0).to(device)\n",
    "    hidden = (torch.zeros(num_layers, 1, hidden_size).to(device),\n",
    "              torch.zeros(num_layers, 1, hidden_size).to(device))\n",
    "    \n",
    "    result = start_string\n",
    "    for _ in range(length):\n",
    "        output, hidden = model(input_eval, hidden)\n",
    "        next_char = torch.argmax(output[:, -1, :], dim=-1).item()\n",
    "        result += int_to_string[next_char]\n",
    "        input_eval = torch.tensor([[next_char]], dtype=torch.long).to(device)\n",
    "    return result\n",
    "\n",
    "print(generate_text(\"Once upon a time\"))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda-gpt",
   "language": "python",
   "name": "cuda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
